%This bibliography is a complete collection of all MIRI Publications. Its contents should reflect the list at https://intelligence.org/all-publications/. Minor variations may occur as papers are submitted to conferences, awaiting publication, etc.
%Created by Jimmy (jimmy@intelligence.org) 2015/08/17

%------ 2001-2009 ------%

@report{Yudkowsky:2001:CreateFAI,
  title = {Creating {F}riendly {AI} 1.0},
  author = {Yudkowsky, Eliezer},
  date = {2001-06-15},
  type = {Working Paper},
  institution = {The Singularity Institute, San Francisco, CA},
  subtitle = {The Analysis and Design of Benevolent Goal Architectures},
  url = {http://intelligence.org/files/CFAI.pdf},
}

@report{Yudkowsky:2004:CoherentVolition,
  title = {Coherent Extrapolated Volition},
  author = {Yudkowsky, Eliezer},
  date = {2004-05},
  institution = {The Singularity Institute, San Francisco, CA},
  type = {Working Paper},
  url = {http://intelligence.org/files/CEV.pdf},
}

@incollection{Yudkowsky:2007:LevelsOfOrg,
  title = {Levels of Organization in General Intelligence},
  author = {Yudkowsky, Eliezer},
  pages = {389--501},
  crossref = {Goertzel:2007},
  doi = {10.1007/978-3-540-68677-4_12},
  %ids = {Yudkowsky:2007a},
}

@incollection{Yudkowsky:2008:CogBias,
  title = {Cognitive Biases Potentially Affecting Judgement of Global Risks},
  author = {Yudkowsky, Eliezer},
  pages = {91--119},
  crossref = {Bostrom:2008},
  %ids = {Yudkowsky:2008a},
}

@incollection{Yudkowsky:2008:AIGlobalRisk,
  title = {Artificial Intelligence as a Positive and Negative Factor in Global Risk},
  author = {Yudkowsky, Eliezer},
  pages = {308--345},
  crossref = {Bostrom:2008},
  %ids = {Yudkowsky:2008},
}

@inproceedings{Shulman:2009:WhichConsequentialism,
  title = {Which Consequentialism? {M}achine Ethics and Moral Divergence},
  author = {Shulman, Carl and Jonsson, Henrik and Tarleton, Nick},
  crossref = {Reynolds:2009},
  pages = {23--25},
}

@inproceedings{Shulman:2009:MachineEthics,
  title = {Machine Ethics and Superintelligence},
  author = {Shulman, Carl and Jonsson, Henrik and Tarleton, Nick},
  crossref = {Reynolds:2009},
  pages = {95--97},
  %ids = {Shulman:2009a},
}

@unpublished{Shulman:2009:ArmsControlIE,
  title = {Arms Control and Intelligence Explosions},
  author = {Shulman, Carl},
  date = {2009-07-02/2009-07-04},
  howpublished = {Paper presented at the 7th European Conference on Computing and Philosophy (ECAP)},
  location = {Bellaterra, Spain},
  %ids = {Shulman:2009b},
}

@unpublished{Rayhawk:2009:FrameOfAI,
  title = {Changing the Frame of {AI} Futurism},
  author = {Rayhawk, Stephen and Salamon, Anna and McCabe, Thomas and Anissimov, Michael and Nelson, Rolf},
  date = {2009-07-02/2009-07-04},
  howpublished = {Paper presented at the 7th European Conference on Computing and Philosophy (ECAP)},
  location = {Bellaterra, Spain},
  subtitle = {From Storytelling to Heavy-Tailed, High-Dimensional Probability Distributions},
}

@report{deBlanc:2009:ConvergenceUtilityUAI,
  title = {Convergence of Expected Utility for {U}niversal {A}rtificial {I}ntelligence},
  author = {de Blanc, Peter},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  type = {Working Paper},
  year = {2013},
  url = {https://intelligence.org/files/Convergence-EU.pdf},
}


%------ 2010 ------%

@report{Yudkowsky:2010:ReducingRiskAI,
  title = {Reducing Long-Term Catastrophic Risks from Artificial Intelligence},
  author = {Yudkowsky, Eliezer and Shulman, Carl and Salamon, Anna and Nelson, Rolf and Kaas, Steven and Rayhawk, Steve and McCabe, Tom},
  year = {2010},
  type = {Working Paper},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  url = {https://intelligence.org/files/ReducingRisks.pdf},
  %ids = {Yudkowsky:2010c},
}

@report{Yudkowsky:2010:TDT,
  title = {Timeless Decision Theory},
  author = {Yudkowsky, Eliezer},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2010},
  url = {http://intelligence.org/files/TDT.pdf},
  %ids = {Yudkowsky:2010},
}

@report{Tarleton:2010:ExtrapVolition,
  title = {Coherent Extrapolated Volition},
  author = {Tarleton, Nick},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2010},
  subtitle = {A Meta-Level Approach to Machine Ethics},
  url = {http://intelligence.org/files/CEV-MachineEthics.pdf},
}

@inproceedings{Sotala:2010:MostlyHarmless,
  title = {From Mostly Harmless to Civilization-Threatening},
  author = {Sotala, Kaj},
  crossref = {Mainzer:2010},
  subtitle = {Pathways to Dangerous Artificial Intelligences},
}

@inproceedings{Shulman:2010:SoftLimitSingularity,
  title = {Implications of a Software-Limited Singularity},
  author = {Shulman, Carl and Sandberg, Anders},
  crossref = {Mainzer:2010},
}

@report{Shulman:2010:WholeBrainEm,
  title = {Whole Brain Emulation and the Evolution of Superorganisms},
  author = {Shulman, Carl},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2010},
  url = {http://intelligence.org/files/WBE-Superorgs.pdf},
  %ids = {Shulman:2010a},
}

@report{Shulman:2010:AIDrivesRisk,
  title = {Omohundro's \mkbibquote{Basic AI Drives} and Catastrophic Risks},
  author = {Shulman, Carl},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2010},
  url = {http://intelligence.org/files/BasicAIDrives.pdf},
  %ids = {Shulman:2010b},
}

@inproceedings{Salamon:2010:IntelligibleIntel,
  title = {How Intelligible is Intelligence?},
  author = {Salamon, Anna and Rayhawk, Steve and Kram{\'{a}}r, J{\'{a}}nos},
  crossref = {Mainzer:2010},
}

@report{Kaas:2010:SoftwareMinds,
  title = {Economic Implications of Software Minds},
  author = {Kaas, Steven and Rayhawk, Steve and Salamon, Anna and Salamon, Peter},
  date = {2010-08-10},
  institution = {The Singularity Institute, San Francisco, CA},
  url = {http://intelligence.org/files/EconomicImplications.pdf},
}

@inproceedings{Fox:2010:Benevolence,
  title = {Superintelligence Does Not Imply Benevolence},
  author = {Fox, Joshua and Shulman, Carl},
  crossref = {Mainzer:2010},
}



%------ 2011 ------%

@report{Yudkowsky:2011:ComplexValueFuture,
  title = {Complex Value Systems are Required to Realize Valuable Futures},
  author = {Yudkowsky, Eliezer},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2011},
  url = {http://intelligence.org/files/ComplexValues.pdf},
  %ids = {Yudkowsky:2011a},
}

@inproceedings{Dewey:2011:LearningValue,
  title = {Learning What to Value},
  author = {Dewey, Daniel},
  year = {2011},
  crossref = {Schmidhuber:2011},
  doi = {10.1007/978-3-642-22887-2_35},
  pages = {309--314},
}

@report{de-Blanc:2011:OntologicalCrisis,
  title = {Ontological Crises in Artificial Agents' Value Systems},
  author = {\autocap{d}e Blanc, Peter},
  date = {2011-05-19},
  institution = {The Singularity Institute, San Francisco, CA},
  archivePrefix = {arXiv},
  eprint = {1105.3821},
  primaryClass = {cs.AI},
}


%------ 2012 ------%

@article{Sotala:2012:CoalescingMinds,
  title = {Coalescing Minds},
  author = {Sotala, Kaj and Valpola, Harri},
  journaltitle = {International Journal of Machine Consciousness},
  subtitle = {Brain Uploading-Related Group Mind Scenarios},
  year = {2012},
  doi = {10.1142/S1793843012400173},
  number = {1},
  pages = {293--312},
  volume = {4},
}

@article{Sotala:2012:AdvantageAI,
  title = {Advantages of Artificial Intelligences, Uploads, and Digital Minds},
  author = {Sotala, Kaj},
  journaltitle = {International Journal of Machine Consciousness},
  year = {2012},
  doi = {10.1142/S1793843012400161},
  number = {1},
  pages = {275--291},
  volume = {4},
  %ids = {Sotala:forthcoming,Sotala:2012a},
}

@article{Shulman:2012:HowHardAI,
  title = {How Hard is Artificial Intelligence? {E}volutionary Arguments and Selection Effects},
  author = {Shulman, Carl and Bostrom, Nick},
  journaltitle = {Journal of Consciousness Studies},
  year = {2012},
  number = {7--8},
  pages = {103--130},
  url = {http://ingentaconnect.com/content/imp/jcs/2012/00000019/F0020007/art00011},
  volume = {19},
  %ids = {Shulman:forthcoming},
}

@techreport{Salamon:2012:SISummitReport,
  title = {Singularity Summit 2011 Workshop Report},
  author = {Salamon, Anna and Muehlhauser, Luke},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2012},
  url = {https://intelligence.org/files/AIR-Bibliography2012.pdf},
}

@report{Muehlhauser:2012:AIRiskBib,
  title = {{AI} Risk Bibliography 2012},
  author = {Muehlhauser, Luke},
  institution = {The Singularity Institute, San Francisco, CA},
  year = {2012},
  type = {Working Paper},
  url = {https://intelligence.org/files/SS11Workshop.pdf},
  %ids = {Muehlhauser:2012f},
}

@inproceedings{Hibbard:2012:DecisionSupport,
  title = {Decision Support for Safe {AI} Design},
  author = {Hibbard, Bill},
  crossref = {Bach:2012},
  doi = {10.1007/978-3-642-35506-6_13},
  pages = {117--125},
  %ids = {Hibbard:2012a},
}

@unpublished{Hibbard:2012:AvoidingBehaviors,
  title = {Avoiding Unintended {AI} Behaviors},
  author = {Hibbard, Bill},
  date = {2012-12-08/2012-12-11},
  howpublished = {Paper presented at the Fifth Conference on Artificial General Intelligence (AGI--12)},
  location = {Oxford},
  url = {http://www.ssec.wisc.edu/~billh/g/hibbard_agi12a.pdf},
  urldate = {2012-12-31},
  comment = {deprecated},
  %ids = {Hibbard:2012c},
}

@inproceedings{Armstrong:2012:PredictingAIFailing,
  title = {How We're Predicting {AI}---or Failing To},
  author = {Armstrong, Stuart and Sotala, Kaj},
  crossref = {Romportl:2012},
  pages = {52--75},
  %ids = {Armstrong:2012b},
}


%------ 2013 ------%

@report{Yudkowsky:2013:TilingAgents,
  title = {Tiling Agents for Self-Modifying {AI}, and the L{\"{o}}bian Obstacle},
  author = {Yudkowsky, Eliezer and Herreshoff, Marcello},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  type = {Early Draft},
  year = {2013},
  url = {http://intelligence.org/files/TilingAgents.pdf},
  %ids = {old-tiling,Yudkowsky:2013b},
}

@report{Yudkowsky:2013:ProcrastParadox,
  title = {The Procrastination Paradox},
  author = {Yudkowsky, Eliezer},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  url = {http://intelligence.org/files/ProcrastinationParadox.pdf},
  type = {Brief Technical Note},
  %ids = {procrastination,procrastination-paradox,Yudkowsky:2013c},
}

@report{Yudkowsky:2013:IEMicroeco,
  title = {Intelligence Explosion Microeconomics},
  author = {Yudkowsky, Eliezer},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  number = {2013--1},
  series = {Technical Report},
  url = {http://intelligence.org/files/IEM.pdf},
}

@incollection{Yudkowsky:2013:FAI,
  title = {Friendly Artificial Intelligence},
  author = {Yudkowsky, Eliezer},
  year = {2013},
  pages = {181--195},
  isbn = {978-3-642-32559-5},
  booktitle = {Singularity Hypotheses},
  booksubtitle = {A Scientific and Philosophical Assessment},
  series = {The Frontiers Collection},
  editor = {Eden, Amnon H. and Moor, James H. and S{\o}raker, Johnny H. and Steinhart, Eric},
  doi = {10.1007/978-3-642-32560-1_10},
  url = {http://dx.doi.org/10.1007/978-3-642-32560-1_10},
  publisher = {Springer Berlin Heidelberg},
  %ids = {Yudkowsky:2013d},
}

@article{Yampolskiy:2012:SafeEngineerAGI,
  title = {Safety Engineering for Artificial General Intelligence},
  author = {Yampolskiy, Roman V. and Fox, Joshua},
  journaltitle = {Topoi},
  year = {2012},
  doi = {10.1007/s11245-012-9128-9},
  %ids = {Yampolskiy:forthcoming,Yampolskiy:2012c},
}

@incollection{Yampolskiy:2012:AGIMentalModel,
  title = {Artificial General Intelligence and the Human Mental Model},
  author = {Yampolskiy, Roman V. and Fox, Joshua},
  crossref = {Eden:2012},
  %ids = {Yampolskiy:2012a},
}

@techreport{Stiennon:2013:RecursiveLogicTheory,
  title = {Recursively-Defined Logical Theories are Well-Defined},
  author = {Stiennon, Nisan},
  institution = {Machine Intelligence Research Institute},
  address = {Berkeley, CA},
  year = {2013},
  number = {2013--8},
  url = {http://intelligence.org/files/RecursivelyDefinedTheories.pdf},
  %ids = {recursively-logical,recursive-theories},
}

@techreport{Soares:2013:FalMonster,
  title = {Fallenstein's Monster},
  author = {Soares, Nate},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2013--7},  
  year = {2013},
  url = {https://intelligence.org/files/FallensteinsMonster.pdf},
}

@report{Sawin:2013:PiProblem,
  title = {Computable Probability Distributions Which Converge on $\Pi_1$ Will Disbelieve True $\Pi_2$ Sentences},
  author = {Sawin, Will and Demski, Abram},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  number = {2013--10},
  url = {http://intelligence.org/files/Pi1Pi2Problem.pdf},
  %ids = {sawin,pi1pi2},
}

@report{Muehlhauser:2013:AdvisorTheoryCEV,
  title = {Ideal Advisor Theories and Personal {CEV}},
  author = {Muehlhauser, Luke and Williamson, Chris},
  institution = {Machine Intelligence Research Institute},
  year = {2013},
  location = {Berkeley, CA},
  url = {http://intelligence.org/files/IdealAdvisorTheories.pdf},
}

@incollection{Muehlhauser:2012:IEEvidenceImport,
  title = {Intelligence Explosion},
  author = {Muehlhauser, Luke and Salamon, Anna},
  crossref = {Eden:2012},
  subtitle = {Evidence and Import},
  %ids = {Muehlhauser:2012b},
}

@incollection{Muehlhauser:2012:IEMachineEthics,
  title = {Intelligence Explosion and Machine Ethics},
  author = {Muehlhauser, Luke and Helm, Louie},
  crossref = {Eden:2012},
  %url = {https://intelligence.org/files/IE-ME.pdf},
}

@online{Muehlhauser:2011:IEFAQ,
  title = {Intelligence Explosion {FAQ}},
  author = {Muehlhauser, Luke},
  url = {http://intelligence.org/ie-faq/},
  organization = {Machine Intelligence Research Institute},
  urldate = {2015-08-26},
  year = {2013},
  %ids = {Muehlhauser:2011a},
}

@report{Hahn:2013:InductionProbMath,
  title = {Scientific Induction in Probabilistic Mathematics},
  author = {Hahn, Jeremy},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  type= {Brief Technical Note},
  url = {http://intelligence.org/files/ScientificInduction.pdf},
  number = {2013--4},
  %ids = {hahn},
}

@techreport{Grace:2013:AlgProgress,
  title = {Algorithmic Progress in Six Domains},
  author = {Grace, Katja},
  institution = {Machine Intelligence Research Institute},
  year = {2013},
  location = {Berkeley, CA},
  number = {2013--3},
  url = {http://intelligence.org/files/AlgorithmicProgress.pdf},
}

@report{Fallenstein:2013:PredictAGI,
  title = {Predicting {AGI}: What Can We Say When We Know So Little?},
  author = {Fallenstein, Benja and Mennen, Alex},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  url = {https://intelligence.org/files/PredictingAGI.pdf},
  type = {Working Paper},
}

@report{Fallenstein:2014:ConsistencyWaterfall,
  title = {An Infinitely Descending Sequence of Sound Theories each Proving the Next Consistent},
  author = {Fallenstein, Benja},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2014},
  url = {http://intelligence.org/files/ConsistencyWaterfall.pdf},
  type = {Brief Technical Note},
  number = {2013--6},
  %ids = {consistency-waterfall,Fallenstein:2014d},
}

@report{Fallenstein:2014:DecreaseMathStrength,
  title = {Decreasing Mathematical Strength in One Formalization of Parametric Polymorphism},
  author = {Fallenstein, Benja},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2014},
  url = {http://intelligence.org/files/DecreasingStrength.pdf},
  type = {Brief Technical Note},
  %ids = {pp-decreasing-strength,Fallenstein:2014e},
}

@report{Fallenstein:2013:TilingAgents510,
  title = {The 5-and-10 Problem and the Tiling Agents Formalism},
  author = {Fallenstein, Benja},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2013},
  url = {https://intelligence.org/files/TilingAgents510.pdf},
  type = {Brief Technical Note},
  number = {2013--9},
  %ids = {Fallenstein:2013a},
}

@report{Christiano:2013:DefineTruthProb,
  title = {Definability of Truth in Probabilistic Logic},
  author = {Christiano, Paul F. and Yudkowsky, Eliezer and Herreshoff, Marcello and B{\'{a}}r{\'{a}}sz, Mih{\'{a}}ly},
  date = {2013-04-02},
  type = {Early Draft},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  url = {https://intelligence.org/files/DefinabilityTruthDraft.pdf},
}

@techreport{Armstrong:2013:RacePrecipice,
  title = {Racing to the Precipice: A Model of Artificial Intelligence Development},
  author = {Armstrong, Stuart and Bostrom, Nick and Shulman, Carl},
  year = {2013},
  institution = {Future of Humanity Institute},
  location = {Oxford, UK},
  number = {2013--1},
  url = {http://www.fhi.ox.ac.uk/wp-content/uploads/Racing-to-the-precipice-a-model-of-artificial-intelligence-development.pdf},
  %ids = {Armstrong:2013},
}

@report{Altair:2013:ComparisonNewcomb,
  title = {A Comparison of Decision Algorithms on Newcomblike Problems},
  author = {Altair, Alex},
  year = {2013},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  url = {http://intelligence.org/files/Comparison.pdf},
  %ids = {Altair:2013},
}

@Book{Muehlhauser:2013:FacingIE,
  title = {Facing the Intelligence Explosion},
  author = {Muehlhauser, Luke},
  year = {2013},
  location = {Berkeley, CA},
  publisher = {Machine Intelligence Research Institute},
  url = {http://intelligenceexplosion.com/},
  %ids = {Muehlhauser:2013a},
}

@Book{Hanson:2013:FoomDebate,
  title = {The {H}anson-{Y}udkowsky {AI}-Foom Debate},
  author = {Hanson, Robin and Yudkowsky, Eliezer},
  year = {2013},
  location = {Berkeley, CA},
  publisher = {Machine Intelligence Research Institute},
  url = {http://intelligence.org/files/AIFoomDebate.pdf},
}


%------ 2014 ------%

@techreport{Yudkowsky:2014:DistribTiling,
  title = {Distributions Allowing Tiling of Staged Subjective {EU} Maximizers},
  author = {Yudkowsky, Eliezer},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2014--1},
  date = {2014-05-11},
  urldate = {2014-05-31},
  userd = {revised},
  url = {http://intelligence.org/files/DistributionsAllowingTiling.pdf},
  %ids = {tiling-distributions,Yudkowsky:2014a},
}

@article{Sotala:2013:ResponseAGIRiskSurvey,
  author = {Sotala, Kaj and Yampolskiy, Roman V.},
  title = {Responses to Catastrophic {AGI} Risk: A Survey},
  journal = {Physica Scripta},
  volume = {90},
  number = {1},
  pages = {018001},
  url = {http://stacks.iop.org/1402-4896/90/i=1/a=018001},
  doi = {10.1088/0031-8949/90/6/069501},
  year = {2014},
  publisher = {IOP Publishing},
  note = {formerly published as technical report 2013--2},
}

@techreport{Soares:2014:Botworld1.1,
  title = {Botworld 1.1},
  author = {Soares, Nate and Fallenstein, Benja},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2014--2},  
  year = {2014},
  url = {http://machine-intelligence.github.io/Botworld/Botworld.pdf},
  %ids = {botworld,Soares:2014d},
}

@techreport{Soares:2014:TilingAgentsGraph,
  title = {Tiling Agents in Causal Graphs},
  author = {Soares, Nate},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2014--5},  
  year = {2014},
  url = {https://intelligence.org/files/TilingAgentsCausalGraphs.pdf},
  %ids = {Soares:2014i},
}

@article{Shulman:2014:EmbryoSelection,
  title = {Embryo Selection for Cognitive Enhancement: Curiosity or Game-Changer?},
  author = {Schulman, Carl and Bostrom, Nick},
  year = {2014},
  journal = {Global Policy},
  volume = {5},
  number = {1},
  pages = {85--92},
  url = {https://intelligence.org/files/EmbryoSelection.pdf},
}

@article{Muehlhauser:2014:ExploratoryEngAI,
  title = {Exploratory Engineering in {AI}},
  author = {Muehlhauser, Luke and Hibbard, Bill},
  year = {2014},
  journal = {Communications of the ACM},
  volume = {57},
  number = {9},
  pages = {32--34},
  doi = {10.1145/2644257},
  url = {https://intelligence.org/files/ExploratoryEngineeringAI.pdf},
  %ids = {Muehlhauser:2014a},
}

@article{Muehlhauser:2014:WhyNeedFAI,
  title = {Why We Need {F}riendly {AI}},
  author = {Muehlhauser, Luke and Bostrom, Nick},
  journal = {Think},
  volume = {13},
  number = {36},
  pages = {41--47},
  year = {2014},
  doi = {10.1017/S1477175613000316},
}

@inproceedings{LaVictoire:2014:PrisDilemmaLob,
  title = {Program Equilibrium in the Prisoner's Dilemma via {L}{\"{o}}b's {T}heorem},
  author = {LaVictoire, Patrick and Fallenstein, Benja and Yudkowsky, Eliezer and B{\'{a}}r{\'{a}}sz, Mih{\'{a}}ly and Christiano, Paul and Herreshoff, Marcello},
  year = {2014},
  booktitle = {Multiagent Interaction without Prior Coordination: Papers from the AAAI-14 Workshop},
  publisher = {AAAI Publications},
  url = {http://www.aaai.org/ocs/index.php/WS/AAAIW14/paper/view/8833},
  %ids = {LaVictoire:2014},
}

@report{Fallenstein:2014:Loudness,
  title = {\mkbibquote{Loudness}},
  author = {Fallenstein, Benja and Stiennon, Nisan},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2014},
  subtitle = {On Priors over Preference Relations},
  url = {http://intelligence.org/files/LoudnessPriors.pdf},
  type = {Brief Technical Note},
  %ids = {loudness,Fallenstein:2014f},
}

@inproceedings{Fallenstein:2014:SelfReferenceEmbedIntel,
  title = {Problems of Self-Reference in Self-Improving Space-Time Embedded Intelligence},
  author = {Fallenstein, Benja and Soares, Nate},
  crossref = {Goertzel:2014},
  doi = {10.1007/978-3-319-09274-4_3},
  pages = {21--32},
  %ids = {diagonalization-stei,diagonalization-in-stei},
}

@report{Fallenstein:2014:ProcrastinationProbLogic,
  title = {Procrastination in Probabilistic Logic},
  author = {Fallenstein, Benja},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  year = {2014},
  url = {http://intelligence.org/files/ProbabilisticLogicProcrastinates.pdf},
  type = {Working Paper},
  %ids = {probabilistic-logic-procrastinates,problogx,Fallenstein:2014c},
}

@techreport{Christiano:2014:NonOmniscience,
  title = {Non-Omniscience, Probabilistic Inference, and Metamathematics},
  author = {Christiano, Paul},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2014--3},
  year = {2014},
  url = {http://intelligence.org/files/Non-Omniscience.pdf},
  %date = {2014-06-22},
  %ids = {christiano,non-omniscience,Christiano:2014a},
}

@inbook{Bostrom:2014:EthicsAI,
  title = {The Ethics of Artificial Intelligence},
  author = {Bostrom, Nick and Yudkowsky, Eliezer},
  editor = {Frankish, Keith and Ramsey, William M.},
  year = {2014},
  booktitle = {The Cambridge Handbook of Artificial Intelligence},
  location = {New York},
  publisher = {Cambridge University Press},
  %crossref = {Frankish:2014},
  %ids = {Bostrom:2014a},
}

@techreport{Benson-Tilsen:2014:UDTSearchOrder,
  title = {{UDT} with Known Search Order},
  author = {Benson-Tilsen, Tsvi},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2014--4},
  year = {2014},
  url = {http://intelligence.org/files/UDTSearchOrder.pdf},
  %date = {2014-08-22},
  %ids = {chicken,tsvi,Benson-Tilsen:2014},
}

@misc{Barasz:2014:RobustCooperation,
  title = {Robust Cooperation in the Prisoner's Dilemma},
  author = {B{\'{a}}r{\'{a}}sz, Mih{\'{a}}ly and LaVictoire, Patrick and Christiano, Paul F. and Fallenstein, Benja and Herreshoff, Marcello and Yudkowsky, Eliezer},
  year = {2014},
  howpublished = {eprint},
  subtitle = {Program Equilibrium via Provability Logic},
  archivePrefix = {arXiv},
  eprint = {1401.5577},
  primaryClass = {cs.GT},
  %ids = {LaVictoire:2013:RobustCooperation},
}

@article{Armstrong:2014:ErrorsInsightsFamousAI,
  author = {Armstrong, Stuart and Sotala, Kaj and {\'{O}}h{\'{E}}igeartaigh, Se{\'{a}}n S.},
  title = {The errors, insights and lessons of famous {AI} predictions---and what they mean for the future},
  journal =  {Journal of Experimental \& Theoretical Artificial Intelligence},
  volume = {26},
  number = {3},
  pages = {317--342},
  year = {2014},
  publisher = {Taylor \& Francis},
  doi = {10.1080/0952813X.2014.895105},
  URL = {http://dx.doi.org/10.1080/0952813X.2014.895105},
  eprint = {http://dx.doi.org/10.1080/0952813X.2014.895105},
}

%%%Smarter Than Us


%------ 2015 ------%

%%%Rationality: from AI to Zombies

@unpublished{Sotala:2015:ConceptLearningAI,
  title = {Concept Learning for Safe Autonomous {AI}},
  author = {Sotala, Kaj},
  year = {2015},
  howpublished = {Paper presented at the 1st International Workshop on {AI} and Ethics, held within the 29th {AAAI} Conference on Artificial Intelligence ({AAAI}-2015)},
  location = {Austin, TX},
  url = {http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10131},
}

@unpublished{Soares:2015:Corrigibility,
  title = {Corrigibility},
  author = {Soares, Nate and Fallenstein, Benja and Yudkowsky, Eliezer and Armstrong, Stuart},
  howpublished = {Paper presented at the 1st International Workshop on {AI} and Ethics, held within the 29th {AAAI} Conference on Artificial Intelligence ({AAAI}-2015)},
  year = {2015},
  location = {Austin, TX},
  url = {http://aaai.org/ocs/index.php/WS/AAAIW15/paper/view/10124},
  %ids = {corrigibility, Soares:2015d},
}

@inproceedings{Soares:2015:CounterpossibleReasoning,
  title = {Two Attempts to Formalize Counterpossible Reasoning in Deterministic Settings},
  author = {Soares, Nate and Fallenstein, Benja},
  pages = {156--165},
  crossref = {Bieger:2015},
  url = {https://intelligence.org/files/CounterpossibleReasoning.pdf},
  %ids = {Soares:2015e},
}

@misc{Soares:2015:TowardIDT,
  author = {Soares, Nate and Fallenstein, Benja},
  title = {Toward Idealized Decision Theory},
  year = {2015},
  howpublished = {eprint},
  archivePrefix = {arxiv},
  primaryClass = {cs.AI},
  eprint = {1507.01986},
  %ids = {Soares:2015f},
}

@techreport{Soares:2015:QuestionsLogicUncertainty,
  title = {Questions of Reasoning Under Logical Uncertainty},
  author = {Soares, Nate and Fallenstein, Benja},
  year = {2015},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--1},
  url = {https://intelligence.org/files/QuestionsLogicalUncertainty.pdf},
  %ids = {lu,Soares:2014c,Soares:2015},
}

@techreport{Soares:2015:ValueLearningProblem,
  title = {The Value Learning Problem},
  author = {Soares, Nate},
  year = {2015},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--4},
  note = {Submitted to Ethical and Moral Considerations in Non-Human Agents, A symposium within AAAI Spring 2016 Symposia series},
  url = {https://intelligence.org/files/ValueLearningProblem.pdf},
  %ids = {vl,Soares:2014g, Soares:2015b},
}

@techreport{Soares:2015:2RealisticWorldModels,
  title = {Formalizing Two Problems of Realistic World-Models},
  author = {Soares, Nate},
  year = {2015},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--3},
  url = {https://intelligence.org/files/RealisticWorldModels.pdf},
  %ids = {wm, Soares:2014a, Soares:2015a},
}

@techreport{Soares:2015:AligningSuperintelBib,
  title = {Aligning Superintelligence with Human Interests},
  subtitle = {An Annotated Bibliography},
  author = {Soares, Nate},
  year = {2015},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--5},
  url = {https://intelligence.org/files/AnnotatedBibliography.pdf},
  %ids = {Soares:2015c},
}

@techreport{LaVictoire:2015:LobTheoremIntro,
  title = {An Introduction to {L}{\"{o}}b's {T}heorem in {MIRI} Research},
  author = {LaVictoire, Patrick},
  institution = {Machine Intelligence Research Institute},
  year = {2015},
  location = {Berkeley, CA},
  number = {2015--6},
  url = {https://intelligence.org/files/lob-notes-IAFF.pdf},
}

@techreport{Grace:2015:AsilomarBio,
  title = {The Asilomar Conference},
  subtitle = {A Case Study in Risk Mitigation},
  author = {Grace, Katja},
  institution = {Machine Intelligence Research Institute},
  year = {2015},
  location = {Berkeley, CA},
  number = {2015--9},
  url = {http://intelligence.org/files/TheAsilomarConference.pdf},
}

@misc{Garrabrant:2015:BenfordTest,
  title = {Asymptotic Logical Uncertainty and The {B}enford Test},
  howpublished = {eprint},
  author = {Garrabrant, Scott and Bhaskar, Siddharth and Demski, Abram and Garrabrant, Joanna and Koleszarik, George and Lloyd, Evan},
  year = {2015},
  archivePrefix = {arXiv},
  eprint = {1510.03370},
  primaryClass = {cs.LG},
  %url = {http://arxiv.org/abs/1510.03370},
  %note = {formerly published as tech report 2015--11. https://intelligence.org/files/AsymptoticLogicalUncertainty.pdf},
}

@inproceedings{Fallenstein:2015:RefOraclesAI,
  title = {Reflective Oracles: A Foundation for Game Theory in Artificial Intelligence},
  author = {Fallenstein, Benja and Taylor, Jessica and Christiano, Paul F.},
  booktitle = {Logic, Rationality, and Interaction},
  editor = {van der Hoek, Wiebe and Holliday, Wesley H. and  Wang, Wen-fang},
  year = {2015},
  booksubtitle = {5th International Workshop, LORI 2015 Taipei, Taiwan, October 28--31, 2015. Proceedings},
  doi = {10.1007/978-3-662-48561-3_34},
  pages = {411--415},
  publisher = {Springer Berlin Heidelberg},
  series = {Lecture Notes in Computer Science},
  volume = {9394},
  url = {http://dx.doi.org/10.1007/978-3-662-48561-3_34},
  isbn = {978-3-662-48560-6},
  %ids = {Fallenstein:2015a},
}

@misc{Fallenstein:2015:RefOraclesGT,
  title = {Reflective Oracles: A Foundation for Classical Game Theory},
  howpublished = {eprint},
  author = {Fallenstein, Benja and Taylor, Jessica and Christiano, Paul F.},
  year = {2015},
  archivePrefix = {arXiv},
  eprint = {1508.04145},
  primaryClass = {cs.AI},
  note = {This is an extended version of \cite{Fallenstein:2015:RefOraclesAI}.},
  %ids = {Fallenstein:2015c},
}

@inproceedings{Fallenstein:2015:SolomonoffAIXI,
  title = {Reflective Variants of Solomonoff Induction and {AIXI}},
  author = {Fallenstein, Benja and Soares, Nate and Taylor,Jessica},
  pages = {60--69},
  crossref = {Bieger:2015},
  url = {https://intelligence.org/files/ReflectiveSolomonoffAIXI.pdf},
  %ids = {Fallenstein:2015b},
}

@techreport{Fallenstein:2015:VingeanRef,
  title = {Vingean Reflection},
  author = {Fallenstein, Benja and Soares, Nate},
  year = {2015},
  subtitle = {Reliable Reasoning for Self-Improving Agents},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--2},
  url = {https://intelligence.org/files/VingeanReflection.pdf},
  %ids = {vr,Fallenstein:2014a},
}


%------ Recent Publications ------%


%UPDATE
@inproceedings{Soares:2015:AligningSuperintel,
  title = {Aligning Superintelligence with Human Interests},
  author = {Soares, Nate and Fallenstein, Benja},
  subtitle = {A Technical Research Agenda},
  year = {\autocap{f}orthcoming},
  crossref = {Miller:2015},
  %doi = {?},
  %pages = {?},
  %note = {Previously published as technical report 2014â€“-8},
  %ids = {Soares:2015g,Soares:2014},
}

  
@techreport{Grace:2015:SzilardNuclear,
  title = {Le{\'{o}} Szil{\'{a}}rd and the Danger of Nuclear Weapons},
  subtitle = {A Case Study in Risk Mitigation},
  author = {Grace, Katja},
  institution = {Machine Intelligence Research Institute},
  year = {2015},
  location = {Berkeley, CA},
  number = {2015--10},
  url = {http://intelligence.org/files/SzilardNuclearWeapons.pdf},
  %ids = {Grace:2015a},
}

@unpublished{Benson-Tilsen:2015:ConvergentInstrumental,
  author = {Benson-Tilsen, Tsvi and Soares, Nate},
  title = {Formalizing Convergent Instrumental Goals},
  year = {2015},
  url = {http://intelligence.org/files/FormalizingConvergentGoals.pdf},
  howpublished = {Accepted to the 2nd International Workshop on {AI}, Ethics and Society, held within the 30th {AAAI} Conference on Artificial Intelligence ({AAAI}-2016)},
  location = {Phoenix, AZ},
  %note = {technical report 2015--13},
}

@unpublished{Taylor:2015:Quantilizers,
  author = {Taylor, Jessica},
  title = {Quantilizers: A Safer Alternative to Maximizers for Limited Optimization},
  year = {2015},
  url = {http://intelligence.org/files/QuantilizersSaferAlternative.pdf},
  howpublished = {Accepted to the 2nd International Workshop on {AI}, Ethics and Society, held within the 30th {AAAI} Conference on Artificial Intelligence ({AAAI}-2016)},
  location = {Phoenix, AZ},
  %note = {technical report 2015--12},
}

@incollection{Fallenstein:2015:ReflectionHOL,
  author = {Fallenstein, Benja and Kumar, Ramana},
  title = {Proof-Producing Reflection for {HOL}},
  year = {2015},
  isbn = {978-3-319-22101-4},
  booktitle = {Interactive Theorem Proving: 6th International Conference, ITP 2015, Nanjing, China, August 24-27, 2015, Proceedings},
  volume = {9236},
  series = {Lecture Notes in Computer Science},
  editor = {Urban, Christian and Zhang, Xingyuan},
  doi = {10.1007/978-3-319-22102-1_11},
  url = {http://dx.doi.org/10.1007/978-3-319-22102-1_11},
  publisher = {Springer International Publishing},
  pages = {170--186},
  %ids = {Fallenstein:2015d},
}

%------ UNPUBLISHED (Not on All Publications) ------%

@techreport{Critch:2015:BoundedLob,
  author = {Critch, Andrew},
  title = {Parametric Bounded L\"{o}b's Theorem and Robust Cooperation of Bounded Agents},
  year = {2015},
  institution = {Machine Intelligence Research Institute},
  location = {Berkeley, CA},
  number = {2015--14},
  url = {http://intelligence.org/files/ParametricBoundedLobsTheorem.pdf},
}

@unpublished{Sotala:2015:DefValuesLearners,
  title = {Defining Human Values for Value Learners},
  author = {Sotala, Kaj},
  year = {2015},
  url = {http://intelligence.org/files/DefiningValuesForValueLearners.pdf},
  howpublished = {Accepted to the 2nd International Workshop on {AI}, Ethics and Society, held within the 30th {AAAI} Conference on Artificial Intelligence ({AAAI}-2016)},
  location = {Phoenix, AZ},
  %ids = {Sotala:2015a},
}

